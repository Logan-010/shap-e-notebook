{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# STARTUP"
      ],
      "metadata": {
        "id": "rj6VBhuz4rzF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Apc0MIpI4KIX"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/openai/shap-e.git\n",
        "%cd shap-e\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3D FROM TEXT"
      ],
      "metadata": {
        "id": "EwmfsTO34Z4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from shap_e.diffusion.sample import sample_latents\n",
        "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
        "from shap_e.models.download import load_model, load_config\n",
        "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "xm = load_model('transmitter', device=device)\n",
        "model = load_model('text300M', device=device)\n",
        "diffusion = diffusion_from_config(load_config('diffusion'))\n",
        "\n",
        "batch_size = 4\n",
        "guidance_scale = 15.0\n",
        "prompt = \"a shark\"\n",
        "\n",
        "latents = sample_latents(\n",
        "    batch_size=batch_size,\n",
        "    model=model,\n",
        "    diffusion=diffusion,\n",
        "    guidance_scale=guidance_scale,\n",
        "    model_kwargs=dict(texts=[prompt] * batch_size),\n",
        "    progress=True,\n",
        "    clip_denoised=True,\n",
        "    use_fp16=True,\n",
        "    use_karras=True,\n",
        "    karras_steps=64,\n",
        "    sigma_min=1e-3,\n",
        "    sigma_max=160,\n",
        "    s_churn=0,\n",
        ")\n",
        "\n",
        "render_mode = 'nerf'  # you can change this to 'stf'\n",
        "size = 64  # this is the size of the renders; higher values take longer to render.\n",
        "\n",
        "cameras = create_pan_cameras(size, device)\n",
        "for i, latent in enumerate(latents):\n",
        "    images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
        "    display(gif_widget(images))"
      ],
      "metadata": {
        "id": "GrktH4484Prd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shap_e.util.notebooks import decode_latent_mesh\n",
        "\n",
        "for i, latent in enumerate(latents):\n",
        "    with open(f'example_mesh_{i}.ply', 'wb') as f:\n",
        "        decode_latent_mesh(xm, latent).tri_mesh().write_ply(f)"
      ],
      "metadata": {
        "id": "4qcFSsEb4VwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3D FROM IMAGE\n",
        "### upload image named corgi.jpg (this will be used as seed image)"
      ],
      "metadata": {
        "id": "x7QEn69q4e1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from shap_e.diffusion.sample import sample_latents\n",
        "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
        "from shap_e.models.download import load_model, load_config\n",
        "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
        "from shap_e.util.image_util import load_image\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "xm = load_model('transmitter', device=device)\n",
        "model = load_model('image300M', device=device)\n",
        "diffusion = diffusion_from_config(load_config('diffusion'))\n",
        "\n",
        "batch_size = 4\n",
        "guidance_scale = 3.0\n",
        "\n",
        "image = load_image(\"example_data/corgi.png\")\n",
        "\n",
        "latents = sample_latents(\n",
        "    batch_size=batch_size,\n",
        "    model=model,\n",
        "    diffusion=diffusion,\n",
        "    guidance_scale=guidance_scale,\n",
        "    model_kwargs=dict(images=[image] * batch_size),\n",
        "    progress=True,\n",
        "    clip_denoised=True,\n",
        "    use_fp16=True,\n",
        "    use_karras=True,\n",
        "    karras_steps=64,\n",
        "    sigma_min=1e-3,\n",
        "    sigma_max=160,\n",
        "    s_churn=0,\n",
        ")\n",
        "\n",
        "render_mode = 'nerf' # you can change this to 'stf' for mesh rendering\n",
        "size = 64 # this is the size of the renders; higher values take longer to render.\n",
        "\n",
        "cameras = create_pan_cameras(size, device)\n",
        "for i, latent in enumerate(latents):\n",
        "    images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
        "    display(gif_widget(images))"
      ],
      "metadata": {
        "id": "1xjbL3Lr4hLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shap_e.util.notebooks import decode_latent_mesh\n",
        "\n",
        "for i, latent in enumerate(latents):\n",
        "    with open(f'example_mesh_{i}.ply', 'wb') as f:\n",
        "        decode_latent_mesh(xm, latent).tri_mesh().write_ply(f)"
      ],
      "metadata": {
        "id": "MSxtZx2_47D5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}